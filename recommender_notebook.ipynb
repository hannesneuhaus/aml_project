{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Movie Recommender\n",
    "\n",
    "## Installation Information\n",
    "This is written using python 3.11. To ensure that this works properly, please ensure that the correct version is used.\n",
    "Install all necessary requirements using the requirements.txt file using the following command\n",
    "pip install -r ./requirements.txt\n",
    "\n",
    "## Usage\n",
    "To receive correct predictions is necessary to use the exact name of the movie as it is used in the training data. The easiest way currently is to copy\n",
    "the name of the movie from the movies.csv file.\n",
    "To interact with the model there are two possible ways. It is possible to give the model movies as a list (compare recommender_notebook, cell six), and then run the method.\n",
    "But there is also a terminal controller that allowes the user to add movies via a simple terminal menu.\n",
    "Running the scripy.py will automatically prepare the data, train the model and start the terminal menu. This will take time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Text\n",
    "import tensorflow_recommenders as tfrs\n",
    "import sys\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the small dataset\n",
    "ds_mov = 'Data/ml-latest-small/movies.csv'\n",
    "ds_rat = 'Data/ml-latest-small/ratings.csv'\n",
    "ds_tags = 'Data/ml-latest-small/tags.csv'\n",
    "\n",
    "# This is the entire dataset, because of it's size this will take a long while to train the model. \n",
    "# ds_mov = 'Data/ml-latest/movies.csv'\n",
    "# ds_rat = 'Data/ml-latest/ratings.csv'\n",
    "# ds_tags = 'Data/ml-latest/tags.csv'\n",
    "\n",
    "\n",
    "df_mov = pd.read_csv(ds_mov)\n",
    "df_rat = pd.read_csv(ds_rat)\n",
    "df_tags = pd.read_csv(ds_tags)\n",
    "df_model = pd.merge(df_rat, df_mov, on='movieId', how='left')\n",
    "df_model = pd.merge(df_model, df_tags, on=['movieId', 'userId'], how='left')\n",
    "df_mov['movieId'] = df_mov['movieId'].astype(str)\n",
    "df_model['userId'] = df_model['userId'].astype(str)\n",
    "df_model['movieId'] = df_model['movieId'].astype(str)\n",
    "df_model['tag'] = df_model['tag'].fillna('').astype(str)\n",
    "df_model = df_model.drop(columns=['timestamp_x', 'timestamp_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_feat = {key: tf.constant(value) for key, value in df_mov.to_dict(orient='list').items()}\n",
    "movies = tf.data.Dataset.from_tensor_slices(mov_feat)\n",
    "\n",
    "rat_feat = {key: tf.constant(value) for key, value in df_model.to_dict(orient='list').items()}\n",
    "ratings = tf.data.Dataset.from_tensor_slices(rat_feat)\n",
    "\n",
    "movies = movies.map(lambda x: x['title'])\n",
    "model_data = ratings.map(lambda x: {'userId': x['userId'], 'title': x['title'], 'rating': x['rating'], 'tag': x['tag']})\n",
    "shuffled = model_data.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "# for example in movies.take(1):\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding)\n",
    "        ])\n",
    "        self.tag_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_tags.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_tags) + 1, embedding)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            user_embedding = self.user_embedding(inputs['userId'])\n",
    "            tag_embedding = self.tag_embedding(inputs['tag'])\n",
    "            return tf.concat([user_embedding, tag_embedding], axis=1)\n",
    "        else:\n",
    "            return self.user_embedding(inputs)\n",
    "\n",
    "\n",
    "class MovieModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_movie_titles.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding*2)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.movie_embedding(inputs)\n",
    "\n",
    "\n",
    "class RecommenderModel(tfrs.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_model = UserModel()\n",
    "        self.movie_model = MovieModel()\n",
    "        self.task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        ))\n",
    "        \n",
    "    def compute_loss(self, features, training=False):\n",
    "\n",
    "        user_embeddings = self.user_model({'userId': features['userId'], 'tag': features['tag']})  \n",
    "        movie_embeddings = self.movie_model(features['title'])\n",
    "\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "embedding = 32\n",
    "\n",
    "unique_user_ids = np.unique([x.numpy().decode('utf-8') for x in model_data.map(lambda x: x['userId'])])\n",
    "unique_movie_titles = np.unique([x.numpy().decode('utf-8') for x in movies])\n",
    "\n",
    "unique_tags = np.unique([\n",
    "    x.numpy().decode('utf-8') for x in model_data.map(lambda x: x['tag']) if x.numpy().decode('utf-8') != ''\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model = RecommenderModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "\n",
    "model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_movies(model, movie_list, movie_dataset, top_k):\n",
    "    movie_embeddings = model.movie_model(tf.constant(movie_list))\n",
    "    \n",
    "    all_movie_titles = [x.numpy().decode('utf-8') for x in movie_dataset]\n",
    "    all_movie_embeddings = model.movie_model(tf.constant(all_movie_titles))\n",
    "    \n",
    "    scores = tf.linalg.matmul(movie_embeddings, all_movie_embeddings, transpose_b=True)\n",
    "    avg_scores = tf.reduce_mean(scores, axis=0) \n",
    "    \n",
    "    top_indices = tf.argsort(avg_scores, direction='DESCENDING').numpy()\n",
    "    recommended_movies = [all_movie_titles[i] for i in top_indices if all_movie_titles[i] not in movie_list][:top_k]\n",
    "    \n",
    "    return recommended_movies\n",
    "\n",
    "list = [['Toy Story (1995)', 'Jumanji (1995)'], \n",
    "        ['Jurassic Park (1993)', 'Jurassic Park III (2001)'], \n",
    "        ['Batman Begins (2005)', 'The Shawshank Redemption (1994)'], \n",
    "        ['Batman Begins (2005)'], ['Lord of the Rings: The Fellowship of the Ring, The (2001)'], \n",
    "        ['Lord of the Rings, Batman'], \n",
    "        ['Zero Dark Thirty (2012)', 'American Sniper (2014)']]\n",
    "\n",
    "['Lord of the Rings, Batman'] # This will result in bad predictions because the model has no idea what Lord of the Rings or Batman is, it has to be the exact title \n",
    "\n",
    "for liked_movies in list:\n",
    "    print(recommend_movies(model, liked_movies, movies, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_controller():\n",
    "    list_of_movies = []\n",
    "    while True:\n",
    "        print ('Welcome to the movie recommender system!')\n",
    "        print ('Please enter what you want to do:')\n",
    "        print ('1. Add a movie you like')\n",
    "        print ('2. Get movie recommendations')\n",
    "        print ('3. List your movies')\n",
    "        print ('4. Clear screen')\n",
    "        print ('5. Exit')\n",
    "        print ('')\n",
    "        sys.stdout.flush() \n",
    "        user_input = input('Enter your choice: ')\n",
    "        if user_input == '1':\n",
    "            movie = input('Enter the name of the movie you like: ')\n",
    "            list_of_movies.append(movie)\n",
    "            print (f'Added {movie} to your list of liked movies.')\n",
    "            print ('')\n",
    "        elif user_input == '2':\n",
    "            recommendations = recommend_movies(model, list_of_movies, movies, top_k=5)\n",
    "            print ('We recommend the following movies:')\n",
    "            for i, movie in enumerate(recommendations):\n",
    "                print (f'{i+1}. {movie}')\n",
    "            print ('')\n",
    "        elif user_input == '3':\n",
    "            print ('You have liked the following movies:')\n",
    "            for i, movie in enumerate(list_of_movies):\n",
    "                print (f'{i+1}. {movie}')\n",
    "            print ('')\n",
    "        elif user_input == '4':\n",
    "            clear_output()\n",
    "        elif user_input == '5':\n",
    "            print ('Thank you for using the movie recommender system!')\n",
    "            break\n",
    "        else:\n",
    "            print ('Invalid input. Please try again.')\n",
    "            print ('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_controller()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not working!\n",
    "\n",
    "The code below is supposed to also take in the genres of the movies. The genres are loaded into the dataset as a ragged Tensor, but embedding the genres results in an error. \n",
    "A ragged Tensor is a 3D Tensor, so it has to be reduced for the embedding proccess. Embedding  requires the shape of a Tensor to be of rank of 2, but it is 3. After reducing the tensor with reduce_mean the shape of the Tensor is of rank 1. I don't know what might cause this issue, and how to properly handle it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the small dataset\n",
    "ds_mov = 'Data/ml-latest-small/movies.csv'\n",
    "ds_rat = 'Data/ml-latest-small/ratings.csv'\n",
    "ds_tags = 'Data/ml-latest-small/tags.csv'\n",
    "\n",
    "# This is the entire dataset, because of it's size this will take a long while to train the model\n",
    "# ds_mov = 'Data/ml-latest/movies.csv'\n",
    "# ds_rat = 'Data/ml-latest/ratings.csv'\n",
    "# ds_tags = 'Data/ml-latest/tags.csv'\n",
    "\n",
    "\n",
    "df_mov = pd.read_csv(ds_mov)\n",
    "df_rat = pd.read_csv(ds_rat)\n",
    "df_tags = pd.read_csv(ds_tags)\n",
    "df_model = pd.merge(df_rat, df_mov, on='movieId', how='left')\n",
    "df_model = pd.merge(df_model, df_tags, on=['movieId', 'userId'], how='left')\n",
    "df_mov['movieId'] = df_mov['movieId'].astype(str)\n",
    "df_model['userId'] = df_model['userId'].astype(str)\n",
    "df_model['movieId'] = df_model['movieId'].astype(str)\n",
    "df_model['tag'] = df_model['tag'].fillna('').astype(str)\n",
    "df_model = df_model.drop(columns=['timestamp_x', 'timestamp_y'])\n",
    "df_model['genres'] = df_model['genres'].apply(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_feat = {key: tf.constant(value) for key, value in df_mov.drop(columns=['genres']).to_dict(orient='list').items()}\n",
    "mov_feat['genres'] = tf.ragged.constant(df_mov['genres'].tolist())\n",
    "\n",
    "\n",
    "movies = tf.data.Dataset.from_tensor_slices(mov_feat)\n",
    "\n",
    "mod_feat = {key: tf.constant(value) for key, value in df_model.drop(columns=['genres']).to_dict(orient='list').items()}\n",
    "mod_feat['genres'] = tf.ragged.constant(df_model['genres'].tolist())\n",
    "ratings = tf.data.Dataset.from_tensor_slices(mod_feat)\n",
    "\n",
    "movies = movies.map(lambda x: {'title': x['title'], 'genres': x['genres']}, )\n",
    "ratings = ratings.map(lambda x: {'userId': x['userId'], 'title': x['title'], 'rating': x['rating'], 'tag': x['tag'], 'genres': x['genres']})\n",
    "\n",
    "\n",
    "\n",
    "for example in ratings.take(1):\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding)\n",
    "        ])\n",
    "        self.tag_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_tags.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_tags) + 1, embedding)\n",
    "        ])\n",
    "                \n",
    "    def call(self, inputs):\n",
    "        if isinstance(inputs, dict):\n",
    "            user_embedding = self.user_embedding(inputs['userId'])\n",
    "            tag_embedding = self.tag_embedding(inputs['tag'])\n",
    "            return tf.concat([user_embedding, tag_embedding], axis=1)\n",
    "        else:\n",
    "            return self.user_embedding(inputs)\n",
    "\n",
    "\n",
    "class MovieModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.movie_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_movie_titles.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding)\n",
    "        ])\n",
    "        self.genres_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_genres.astype(str), mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_genres) + 1, embedding)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        title_embedding = self.movie_embedding(inputs['title'])\n",
    "        genres_embedding = self.genres_embedding(inputs['genres'])\n",
    "        # genres_embedding = tf.reduce_mean(genres_embedding, axis=1)\n",
    "        \n",
    "        return tf.concat([title_embedding, genres_embedding], axis=1)\n",
    "\n",
    "class RecommenderModel(tfrs.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_model = UserModel()\n",
    "        self.movie_model = MovieModel()\n",
    "        self.task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        ))\n",
    "        \n",
    "    def compute_loss(self, features, training=False):\n",
    "\n",
    "        user_embeddings = self.user_model({'userId': features['userId'], 'tag': features['tag']})  \n",
    "        movie_embeddings = self.movie_model({'title': features['title'], 'genres': features['genres']})\n",
    "\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "embedding = 32\n",
    "\n",
    "unique_user_ids = np.unique([x.numpy().decode('utf-8') for x in ratings.map(lambda x: x['userId'])])\n",
    "unique_movie_titles = np.unique([x.numpy().decode('utf-8') for x in movies.map(lambda x: x['title'])])\n",
    "unique_genres = np.unique([x for x in df_mov['genres'].explode()])\n",
    "unique_tags = np.unique([\n",
    "    x.numpy().decode('utf-8') for x in ratings.map(lambda x: x['tag']) if x.numpy().decode('utf-8') != ''\n",
    "])\n",
    "\n",
    "model = RecommenderModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "\n",
    "cached_train = ratings.shuffle(80_000).batch(8192).cache()\n",
    "model.fit(cached_train, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
